{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.classify import accuracy\n",
    "\n",
    "\n",
    "def process_lang(x):\n",
    "    # Remove web addresses and non-letter characters and make lower case. Stematize and lematize words and remove stop words\n",
    "    l = nltk.word_tokenize(re.sub(\"[\\W\\d]+\",\" \", re.sub(\"(https?://|www\\.|@)\\S*\", \"\", x)).lower())\n",
    "    lem, ste = WordNetLemmatizer(), EnglishStemmer()\n",
    "    l = [ste.stem(lem.lemmatize(i)) for i in l]\n",
    "    return [i for i in l if i not in stopwords.words('english')]\n",
    "\n",
    "\n",
    "def create_classifier(f, n=0):\n",
    "    # Creates a Native BayesClassifier from sample data f with number of rows n. If no value given for n, will use length of target dataset. \n",
    "    s = pd.read_csv(f)\n",
    "    if n != 0 and n < len(s):\n",
    "        s = s.sample(n).reset_index(drop=True)\n",
    "    # Create new text column with web addresses and non-letter characters removed and made lower case. Stem and lematize words and remove stop words\n",
    "    s[\"text_processed\"] = s[\"text\"].apply(lambda x: process_lang(x))\n",
    "    # Create list of the 5000 most common words\n",
    "    wf = FreqDist([i for j in list(s[\"text_processed\"]) for i in j]).most_common(5000)\n",
    "    words = [w[0] for w in wf]\n",
    "    # Create feature table showing which words are contained in which tweets\n",
    "    feat = [({w:w in s.loc[i,\"text_processed\"] for w in words}, s.loc[i,\"target\"]) for i in range(len(s))]\n",
    "    # Split into train and test data (80% train)\n",
    "    tr, te = feat[:int(len(s)*0.8)], feat[int(len(s)*0.8):]\n",
    "    return NaiveBayesClassifier.train(tr), tr, te\n",
    "\n",
    "location = \"../../../../Other/Large Data/Sentiment140.csv\"\n",
    "classifier, train, test = create_classifier(location, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.709"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Accuracy\n",
    "accuracy(classifier, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    hurt = True                0 : 4      =     15.2 : 1.0\n",
      "                  welcom = True                4 : 0      =     13.5 : 1.0\n",
      "                    wont = True                0 : 4      =     11.8 : 1.0\n",
      "                     sad = True                0 : 4      =     10.2 : 1.0\n",
      "                    poor = True                0 : 4      =      9.8 : 1.0\n",
      "                     ugh = True                0 : 4      =      9.5 : 1.0\n",
      "                    sick = True                0 : 4      =      9.3 : 1.0\n",
      "                    alon = True                0 : 4      =      9.1 : 1.0\n",
      "                 congrat = True                4 : 0      =      8.2 : 1.0\n",
      "                    gone = True                0 : 4      =      7.9 : 1.0\n",
      "                    shit = True                0 : 4      =      7.8 : 1.0\n",
      "                  father = True                0 : 4      =      7.8 : 1.0\n",
      "                    lost = True                0 : 4      =      7.7 : 1.0\n",
      "                    foot = True                0 : 4      =      7.1 : 1.0\n",
      "                 perfect = True                4 : 0      =      6.9 : 1.0\n",
      "                    hate = True                0 : 4      =      6.8 : 1.0\n",
      "                     die = True                0 : 4      =      6.5 : 1.0\n",
      "                    damn = True                0 : 4      =      6.5 : 1.0\n",
      "                    lose = True                0 : 4      =      6.4 : 1.0\n",
      "                    ball = True                0 : 4      =      6.4 : 1.0\n",
      "                  stupid = True                0 : 4      =      6.3 : 1.0\n",
      "                    agre = True                4 : 0      =      6.3 : 1.0\n",
      "                    moon = True                4 : 0      =      6.3 : 1.0\n",
      "                    nite = True                4 : 0      =      6.3 : 1.0\n",
      "                    miss = True                0 : 4      =      5.8 : 1.0\n",
      "                   smile = True                4 : 0      =      5.7 : 1.0\n",
      "                     boo = True                0 : 4      =      5.7 : 1.0\n",
      "                   didnt = True                0 : 4      =      5.7 : 1.0\n",
      "                 tuesday = True                0 : 4      =      5.7 : 1.0\n",
      "                       h = True                0 : 4      =      5.7 : 1.0\n",
      "            followfriday = True                4 : 0      =      5.6 : 1.0\n",
      "                   funni = True                4 : 0      =      5.2 : 1.0\n",
      "                     bad = True                0 : 4      =      5.1 : 1.0\n",
      "                      st = True                0 : 4      =      5.1 : 1.0\n",
      "                unfortun = True                0 : 4      =      5.1 : 1.0\n",
      "                    fill = True                0 : 4      =      5.1 : 1.0\n",
      "                 jealous = True                0 : 4      =      5.1 : 1.0\n",
      "                 stomach = True                0 : 4      =      5.1 : 1.0\n",
      "                   delay = True                0 : 4      =      5.1 : 1.0\n",
      "                    neck = True                0 : 4      =      5.1 : 1.0\n",
      "                     flu = True                0 : 4      =      5.1 : 1.0\n",
      "                       k = True                4 : 0      =      4.9 : 1.0\n",
      "                  parent = True                4 : 0      =      4.9 : 1.0\n",
      "                 mention = True                4 : 0      =      4.9 : 1.0\n",
      "                twilight = True                4 : 0      =      4.9 : 1.0\n",
      "                      ff = True                4 : 0      =      4.9 : 1.0\n",
      "                    bore = True                0 : 4      =      4.8 : 1.0\n",
      "                   iphon = True                0 : 4      =      4.8 : 1.0\n",
      "                  hahaha = True                4 : 0      =      4.7 : 1.0\n",
      "                    crap = True                0 : 4      =      4.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Check most informative features\n",
    "classifier.show_most_informative_features(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
