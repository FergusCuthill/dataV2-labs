{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandatory Challenge\n",
    "## Context\n",
    "You work in the data analysis team of a very important company. On Monday, the company shares some good news with you: you just got hired by a major retail company! So, let's get prepared for a huge amount of work!\n",
    "\n",
    "Then you get to work with your team and define the following tasks to perform:   \n",
    "1. You need to start your analysis using data from the past.  \n",
    "2. You need to define a process that takes your daily data as an input and integrates it.  \n",
    "\n",
    "You are in charge of the second part, so you are provided with a sample file that you will have to read daily. To complete you task, you need the following aggregates:\n",
    "* One aggregate per store that adds up the rest of the values.\n",
    "* One aggregate per item that adds up the rest of the values.\n",
    "\n",
    "You can import the dataset `warehouse_and_retail_sales` from Ironhack's database. \n",
    "\n",
    "## Your task\n",
    "Therefore, your process will consist of the following steps:\n",
    "1. Read the sample file that a daily process will save in your folder. \n",
    "2. Clean up the data.\n",
    "3. Create the aggregates.\n",
    "4. Write three tables in your local database: \n",
    "    - A table for the cleaned data.\n",
    "    - A table for the aggregate per supplier.\n",
    "    - A table for the aggregate per item.\n",
    "\n",
    "## Instructions\n",
    "* Read the csv you can find in Ironhack's database.\n",
    "* Clean the data and create the aggregates as you consider.\n",
    "* Create the tables in your local database.\n",
    "* Populate them with your process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# I've placed all of the details of the actual code to process data in this box. Any checks I've done are detailed\n",
    "# in the boxes below. \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import raw data from file. Not sure if the import file name is likely to change. Would have to consider ways to update\n",
    "# imp_file in the cases that it might. \n",
    "imp_file = \"../Raw_Data/Warehouse_and_Retail_Sales.csv\"\n",
    "data = pd.read_csv(imp_file)\n",
    "# Replace null values with **BLANK**\n",
    "data[[\"SUPPLIER\", \"ITEM TYPE\"]] = data[[\"SUPPLIER\", \"ITEM TYPE\"]].fillna(\"**BLANK**\")\n",
    "# Group data by supplier\n",
    "supplier_agg = data.groupby([\"SUPPLIER\"])[[\"RETAIL SALES\",\"RETAIL TRANSFERS\",\"WAREHOUSE SALES\"]].sum()\n",
    "# Group data by item - using ITEM CODE instead of ITEM DESCRIPTION as this is more likely to be specific. \n",
    "item_agg = data.groupby([\"ITEM CODE\"])[[\"RETAIL SALES\",\"RETAIL TRANSFERS\",\"WAREHOUSE SALES\"]].sum()\n",
    "# Export cleaned data\n",
    "data.to_csv(\"../Output/Warehouse_and_Retail_Sales_Cleaned.csv\", index = False)\n",
    "supplier_agg.to_csv(\"../Output/Warehouse_and_Retail_Sales_Agg_by_Supplier.csv\")\n",
    "item_agg.to_csv(\"../Output/Warehouse_and_Retail_Sales_Cleaned_Agg_by_Item.csv\")\n",
    "\n",
    "# I've obviously not made a great deal of changes to the data here however, having looked over the data, I don't \n",
    "# particularly feel justified in making any other changes. I'll have a go at the other challenges at some point over the \n",
    "# weekend so I can hopefully get the practice making changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR                 0\n",
      "MONTH                0\n",
      "SUPPLIER            24\n",
      "ITEM CODE            0\n",
      "ITEM DESCRIPTION     0\n",
      "ITEM TYPE            1\n",
      "RETAIL SALES         0\n",
      "RETAIL TRANSFERS     0\n",
      "WAREHOUSE SALES      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Null values check\n",
    "null_cols = data.isnull().sum()\n",
    "print(null_cols)\n",
    "# From looking at the null values in the supplier column, these appear to be credit values. Will change these to **BLANK**.\n",
    "# Hopefully this is clear. \n",
    "# There is also a null value in the ITEM TYPE column. A quick google says this should be wine in this case but there is no\n",
    "# way to guarentee that missing values will be wine in future. Again I think **BLANK** is a better option. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorrect values checks\n",
    "# Years are all 2017 or 2018\n",
    "# Months are all ints from 1-12\n",
    "# Suppliers - a couple of the supplier names might be duplicates but this may be linked companies or deliberate for for\n",
    "# another reason. One is called Default. Not clear what this refers to. \n",
    "# Item type - all values seem reasonable\n",
    "# Retail sales - some -ve values. Might relate to returns though. \n",
    "# Same for retail transfers\n",
    "# Warehouse sales. This has some large -ve values but those values do look to be related to returns such as empty kegs and \n",
    "# credits. \n",
    "# Item descriptions and codes do not always match up perfectly. There are codes with multiple descriptions and descriptions\n",
    "# with multiple codes. Will preferentially consider item codes as this is more likely to refer to specific items though\n",
    "# this is far from guarenteed. \n",
    "\n",
    "# Low variance\n",
    "# A cursory check of the data shows that all columns are useful\n",
    "\n",
    "# Extreme values\n",
    "# No values appear particularly extreme. Could remove outside of a range however, sorting the data even the highest values\n",
    "# appear to be reasonable. \n",
    "\n",
    "# Special characters\n",
    "# I'm not sure that there is currently any justification for removing these\n",
    "\n",
    "# Duplicates\n",
    "# In this case duplicates are likely to refer to separate orders and so should be preserved. \n",
    "\n",
    "# Column Names\n",
    "# Appear perfectly sensible. No point upsetting the apple cart by changing things. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEAR                  int64\n",
       "MONTH                 int64\n",
       "SUPPLIER             object\n",
       "ITEM CODE            object\n",
       "ITEM DESCRIPTION     object\n",
       "ITEM TYPE            object\n",
       "RETAIL SALES        float64\n",
       "RETAIL TRANSFERS    float64\n",
       "WAREHOUSE SALES     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes\n",
    "# Supplier, Item Code, Item Description and Item Type are all set to object. Is there any disadvantage to this? I could\n",
    "# change them to string if there is a geunine benefit to doing so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128355, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
